{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import gc\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = 'Data/dataset.hdf5'\n",
    "subtract_mean = True\n",
    "\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file[\"train_mean\"][...,0]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "\n",
    "data_num = hdf5_file[\"train_flow\"].shape[0]\n",
    "    \n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "flow_rows, flow_cols = 298, 17\n",
    "\n",
    "x_train = hdf5_file[\"train_flow\"][...,0]\n",
    "if subtract_mean:\n",
    "    x_train -= mm\n",
    "\n",
    "y_train = hdf5_file[\"train_labels\"][:,...]\n",
    "hdf5_file.close()\n",
    "hdf5_path = 'Data/dataset-IoT.hdf5'\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "\n",
    "x_test = hdf5_file[\"IoT_flow\"][...,0]\n",
    "if subtract_mean:\n",
    "    x_test -= mm\n",
    "\n",
    "y_test = hdf5_file[\"labels\"][:,...]\n",
    "\n",
    "hdf5_file.close()\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "    \n",
    "    \n",
    "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "accuracy: 88.57413%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 87.48820%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 87.58262%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.29084%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.47970%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.14920%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 87.77148%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.62134%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 85.78848%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 89.14070%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.19641%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 89.28234%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 87.58262%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.81020%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.05477%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 87.44098%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 87.96034%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.04913%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 88.04913%\n",
      "[2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76, 78]\n",
      "accuracy: 89.13557%\n",
      "88.12241% (+/- 0.76021%)\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "kfold = StratifiedKFold(n_splits=20, shuffle=True)\n",
    "cvscores = []\n",
    "\n",
    "for train, test in kfold.split(x_train, y_train):\n",
    "    num_classes = 2\n",
    "    high = 80\n",
    "    \n",
    "    filter_lenghts =  [int(i) for i in np.arange(2,high,2)]\n",
    "    print(filter_lenghts)\n",
    "    convs = []\n",
    "    maxlen = 298\n",
    "    batch_size = 1024\n",
    "    epochs = 30\n",
    "    numFilters=128\n",
    "    activations= \"sigmoid\"\n",
    "    dropoutVal = 0.2485206320388983\n",
    "    lr = 0.001362881122433337\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "\n",
    "    optim = adam\n",
    "    y_train_k = keras.utils.to_categorical(y_train[train], num_classes)\n",
    "    y_test_k = keras.utils.to_categorical(y_train[test], num_classes)\n",
    "    \n",
    "    input_flow = Input(shape=input_shape)\n",
    "\n",
    "    convs= {}\n",
    "    mpoolings = {}\n",
    "    flattens = {}\n",
    "    convs_out = []\n",
    "    for i in filter_lenghts:\n",
    "        convs[str(i)+'_convolution']=Conv1D(filters=numFilters,kernel_size=i,padding=\"valid\",activation=activations,strides=1)(input_flow)\n",
    "\n",
    "        mpoolings[str(i)+'_maxpooling'] = MaxPooling1D(pool_size= maxlen - i + 1)(convs[str(i)+'_convolution'])\n",
    "        flattens[str(i)+'_flattenout'] = Flatten()(mpoolings[str(i)+'_maxpooling'])\n",
    "        convs_out.append(flattens[str(i)+'_flattenout'])\n",
    "    out = Concatenate()(convs_out)\n",
    "    dropout = Dropout(dropoutVal)(out)\n",
    "    dense = Dense(64, activation='relu')(dropout)\n",
    "    dense2 = Dense(32, activation='relu')(dense)\n",
    "    dropout2 = Dropout(dropoutVal)(dense2)\n",
    "    end = Dense(num_classes, activation='softmax')(dropout2)\n",
    "\n",
    "    model = Model(inputs=input_flow, outputs=end) \n",
    "    #model.summary()\n",
    "    try:\n",
    "        model = multi_gpu_model(model, gpus = 4)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    model.fit(x_train[train],y_train_k, batch_size=batch_size, epochs=epochs, verbose=0, class_weight=class_weights, shuffle=True)\n",
    "    scores = model.evaluate(x_train[test], y_test_k, verbose=0)\n",
    "    \n",
    "    print(\"%s: %.5f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[88.57412934303284,\n",
       " 87.48819828033447,\n",
       " 87.58262395858765,\n",
       " 88.29084038734436,\n",
       " 88.47969770431519,\n",
       " 88.14919590950012,\n",
       " 87.77148127555847,\n",
       " 88.62134218215942,\n",
       " 85.78848242759705,\n",
       " 89.14070129394531,\n",
       " 88.19640874862671,\n",
       " 89.28233981132507,\n",
       " 87.58262395858765,\n",
       " 88.81019949913025,\n",
       " 88.05477023124695,\n",
       " 87.44097948074341,\n",
       " 87.9603385925293,\n",
       " 88.04912567138672,\n",
       " 88.04912567138672,\n",
       " 89.13556933403015]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
